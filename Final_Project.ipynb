{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4447 Final Project - Predicting Real Disasters from Tweets\n",
    "## Hafez Gharbiah, Tyler Christeson\n",
    "## data: https://www.kaggle.com/vbmokin/nlp-with-disaster-tweets-cleaning-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric + Guidelines\n",
    "1. Proper tagging of Github repository for final report as per deadlines (0.5 = 0.25 + 0.25 points)\n",
    "1. Dataset and motivation slide (1 points)\n",
    "    - How/why the dataset was collected and a description of the metadata of your dataset.\n",
    "1. Actual task definition/research question (2 points)\n",
    "    - What real-world problem are you trying to solve? What are the input and output of your analysis?\n",
    "1. Literature review (2 points)\n",
    "    - What other work has been done in this area, and how is your work novel compared to others?\n",
    "1. Quality of cleaning (6 points, 2 points each) \n",
    "    - Data cleaning and type conversion activity. Please share anything unusual you faced during this activity.\n",
    "    - What did you do about missing values and why? Handling missing values properly is very important.\n",
    "    - New feature/attribute creation and data summary statistics and interpretation.\n",
    "1. Visualization (8 points, 2 points each)\n",
    "    - Data visualization activity (box plot, bar plot, violin plot, and pairplot to see relationships and distribution, etc.).\n",
    "    - Describe anything you find in the data after each visualization.\n",
    "    - What data visualization helped you understand about data distribution.\n",
    "    - What you did about possible outlier as per data distribution visualization. (Did you confirm with your client whether it is actually an outlier or put a disclosure statement in your notebook if you decided to remove it?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The problem we're trying to solve is predicting whether a tweet is about a real disaster or not, which can be used to determine if emergency services need to be sent.\n",
    "\n",
    "- We have a collection of 10,000 tweets. The attributes of the dataset are a unique identifier for each tweet, text of the tweet, where the tweet was sent from, keywords that could be used to identify disasters, and whether or not it is about a real disaster (only on some of them).\n",
    "\n",
    "- Examples of records:\n",
    "    - \"Heard about # earthquake is different cities, stay safe everyone .\" \n",
    "    - \"Please like and share our new page for our Indoor Trampoline Park Aftershock opening this fall !\" \n",
    "    - \" nowplaying Alfons - Ablaze 2015 on Puls Radio pulsradio\" \n",
    "    - \"Coincidence Or # Curse ? Still # Unresolved Secrets From Past # accident\"\n",
    "\n",
    "- This is a noisy data set because the tweets are not all about disasters, and certain disaster keywords are used in contexts that are not disasters . For example, while \"ablaze\" is used in several real disaster tweets about ongoing fires, in the above example it is used as a song title. The same is true for many keywords, like \"accident\" and \"aftershock\" above.\n",
    "\n",
    "- Feature engineering can be used in this dataset to:\n",
    "    - extract years to see if we're tweeting about events that aren't current\n",
    "    - extract news network name to determine if the accident is being reported on or not\n",
    "    - topic modeling to extract relevant topics as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /root/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "body%20bags              40\n",
       "harm                     37\n",
       "armageddon               37\n",
       "ruin                     36\n",
       "deluge                   36\n",
       "wrecked                  36\n",
       "explode                  35\n",
       "siren                    35\n",
       "fear                     35\n",
       "twister                  35\n",
       "panic                    34\n",
       "aftershock               34\n",
       "screaming                34\n",
       "sinking                  33\n",
       "blaze                    33\n",
       "traumatised              33\n",
       "blazing                  33\n",
       "crush                    33\n",
       "blizzard                 33\n",
       "upheaval                 32\n",
       "hellfire                 32\n",
       "body%20bag               32\n",
       "bloody                   32\n",
       "curfew                   32\n",
       "collide                  31\n",
       "electrocute              31\n",
       "smoke                    31\n",
       "panicking                31\n",
       "blew%20up                31\n",
       "screamed                 30\n",
       "                         ..\n",
       "sandstorm                 9\n",
       "terrorist                 8\n",
       "evacuation                8\n",
       "inundation                8\n",
       "hailstorm                 8\n",
       "bush%20fires              7\n",
       "drought                   7\n",
       "casualties                7\n",
       "violent%20storm           7\n",
       "thunderstorm              7\n",
       "bridge%20collapse         6\n",
       "airplane%20accident       5\n",
       "mass%20murder             5\n",
       "forest%20fires            5\n",
       "buildings%20on%20fire     5\n",
       "radiation%20emergency     4\n",
       "wild%20fires              4\n",
       "forest%20fire             4\n",
       "razed                     4\n",
       "evacuated                 4\n",
       "wildfire                  4\n",
       "rescuers                  3\n",
       "suicide%20bomb            3\n",
       "nuclear%20disaster        3\n",
       "bombing                   2\n",
       "outbreak                  1\n",
       "typhoon                   1\n",
       "oil%20spill               1\n",
       "suicide%20bomber          1\n",
       "suicide%20bombing         1\n",
       "Name: keyword, Length: 218, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "traindf = pd.read_csv('train_data_cleaning.csv',index_col=0)\n",
    "testdf = pd.read_csv('test_data_cleaning.csv',index_col=0)\n",
    "traindf.keyword[traindf.target==0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality of cleaning (6 points, 2 points each)\n",
    "### Data cleaning and type conversion activity. Please share anything unusual you faced during this activity.\n",
    "### What did you do about missing values and why? Handling missing values properly is very important.\n",
    "### New feature/attribute creation and data summary statistics and interpretation. \n",
    "train_text = traindf.text\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "train_text = [nltk.word_tokenize(i) for i in train_text]\n",
    "train_text = [[w.lower() for w in train_text[i] if w not in stopwords] for i in range(len(train_text))]\n",
    "\n",
    "wnetl = WordNetLemmatizer()\n",
    "\n",
    "def nltk_tag_pos(tag):   \n",
    "    #adapted from https://stackoverflow.com/questions/15586721/wordnet-lemmatization-and-pos-tagging-in-python\n",
    "    if tag[0]=='J':\n",
    "        return wordnet.ADJ\n",
    "    elif tag[0]=='V':\n",
    "        return wordnet.VERB\n",
    "    elif tag[0]=='N':\n",
    "        return wordnet.NOUN\n",
    "    elif tag[0]=='R':\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return wordnet.NOUN #noun is default lemmatize POS\n",
    "    \n",
    "train_text_POS = [nltk.pos_tag(i) for i in train_text]    \n",
    "train_text = [[wnetl.lemmatize(i[0],nltk_tag_pos(i[1])) for i in j] for j in train_text_POS]\n",
    "train_text = [' '.join(train_text[i]) for i in range(len(train_text))]\n",
    "\n",
    "traindf.text = train_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words model\n",
    "cv = CountVectorizer(max_features=1000)\n",
    "x= cv.fit_transform(train_text).toarray()\n",
    "y = traindf.target.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1209   79]\n [ 435  561]]\nModel accuracy is: 0.7749562171628721\nRandomly assigning \"target\" status would result in accuracy of : 0.4296597924602653\n"
     ]
    }
   ],
   "source": [
    "#70:30 train-test split\n",
    "xtrain, xtest, ytrain, ytest = sklearn.model_selection.train_test_split(x,y,test_size=0.3,random_state=1234)\n",
    "\n",
    "import sklearn.naive_bayes\n",
    "classifier = sklearn.naive_bayes.GaussianNB()\n",
    "classifier.fit(xtrain,ytrain)\n",
    "\n",
    "ypred = classifier.predict(xtest)\n",
    "ypred\n",
    "\n",
    "confusionMatrix = sklearn.metrics.confusion_matrix(ytest,ypred)\n",
    "print(confusionMatrix)\n",
    "tn, fp, fn, tp = confusionMatrix.ravel()\n",
    "accuracy = (tp+tn)/(sum(sum(confusionMatrix)))\n",
    "print(f'Model accuracy is: {accuracy}')\n",
    "print(f'Randomly assigning \"target\" status would result in accuracy of : {traindf.target.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = sklearn.model_selection.train_test_split(traindf.text, traindf.target, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1164  124]\n [ 323  673]]\nModel accuracy is: 0.8042907180385289\nRandomly assigning \"target\" status would result in accuracy of : 0.4296597924602653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(xtrain, ytrain)\n",
    "            \n",
    "ypred = nb.predict(xtest)\n",
    "\n",
    "confusionMatrix = sklearn.metrics.confusion_matrix(ytest,ypred)\n",
    "print(confusionMatrix)\n",
    "tn, fp, fn, tp = confusionMatrix.ravel()\n",
    "accuracy = (tp+tn)/(sum(sum(confusionMatrix)))\n",
    "print(f'Model accuracy is: {accuracy}')\n",
    "print(f'Randomly assigning \"target\" status would result in accuracy of : {traindf.target.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1235   53]\n [ 461  535]]\nModel accuracy is: 0.7749562171628721\nRandomly assigning \"target\" status would result in accuracy of : 0.4296597924602653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(xtrain, ytrain)\n",
    "\n",
    "ypred = sgd.predict(xtest)\n",
    "\n",
    "confusionMatrix = sklearn.metrics.confusion_matrix(ytest,ypred)\n",
    "print(confusionMatrix)\n",
    "tn, fp, fn, tp = confusionMatrix.ravel()\n",
    "accuracy = (tp+tn)/(sum(sum(confusionMatrix)))\n",
    "print(f'Model accuracy is: {accuracy}')\n",
    "print(f'Randomly assigning \"target\" status would result in accuracy of : {traindf.target.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1011  277]\n",
      " [ 274  722]]\n",
      "Model accuracy is: 0.7587565674255692\n",
      "Randomly assigning \"target\" status would result in accuracy of : 0.4296597924602653\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(xtrain, ytrain)\n",
    "\n",
    "ypred = logreg.predict(xtest)\n",
    "\n",
    "confusionMatrix = sklearn.metrics.confusion_matrix(ytest,ypred)\n",
    "print(confusionMatrix)\n",
    "tn, fp, fn, tp = confusionMatrix.ravel()\n",
    "accuracy = (tp+tn)/(sum(sum(confusionMatrix)))\n",
    "print(f'Model accuracy is: {accuracy}')\n",
    "print(f'Randomly assigning \"target\" status would result in accuracy of : {traindf.target.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}